{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "## Part II - Practical\n",
    "## Mahla Entezari 401222017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the beginning of the project, I have imported the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " # pip install hazm --upgrade --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip uninstall hazm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'triu' from 'scipy.linalg' (D:\\Uni\\Term 4\\Machine learning\\qenv\\lib\\site-packages\\scipy\\linalg\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m triu\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhazm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhazm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Normalizer, word_tokenize, stopwords_list, POSTagger, DependencyParser\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'triu' from 'scipy.linalg' (D:\\Uni\\Term 4\\Machine learning\\qenv\\lib\\site-packages\\scipy\\linalg\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import xgboost as xgb\n",
    "import re\n",
    "from scipy.linalg import triu\n",
    "from hazm import *\n",
    "from hazm import Normalizer, word_tokenize, stopwords_list, POSTagger, DependencyParser\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# from farsispellchecker import SpellChecker\n",
    "import stanza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this piece of code, I take a list of stop words from the hazm library, in other words, words such as conjunctions and prepositions and frequently used words that do not affect the overall meaning and concept of the sentence and are used in most topics and are frequently used and frequently used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "persian_stopwords = set(stopwords_list())\n",
    "persian_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I define functions that are called below in the preprocessing function. Functions like clean_code, normalize_text, remove_diacritics, preprocess_with_stanza, named_entity_recognition, extract_relations, spell_checker,..\n",
    "\n",
    "- ##### *clean_text*, *normalize_text*, *remove_diacritics*\n",
    "  It works in such a way that it removes prepositions such as space, normalizes it, and also removes stop words and similar tasks.\\\n",
    "  Or, for example, it unites letters such as ک and ی which may be written in several ways.\n",
    "\n",
    "- ##### *preprocess_with_stanza*\n",
    "  It tokenizes input text using Stanza's natural language processing tools, extracting various linguistic features such as lemma, part-of-speech tags,    dependency relations, and named entity recognition labels for each word, returning them as a list of dictionaries representing each word's features\n",
    "\n",
    "- ##### *named_entity_recognition*\n",
    "  This function utilizes Stanza to perform named entity recognition (NER) on Persian text.\\\n",
    "  It downloads the necessary model, processes the text through Stanza's pipeline, and prints detected entities with their types, as well as words with their syntactic dependencies (head and dependency relation).\n",
    "\n",
    "- ##### *extract_relations*\n",
    "  This function processes a Stanza doc object, extracting relations between entities in Persian text sentences.\\\n",
    "  It identifies potential subject, object, indirect object, and modifier relationships (nsubj, obj, iobj, amod) and includes them in relations if both the dependent and head words are recognized entities.\\\n",
    "  It then prints and returns a list of tuples representing these relations.\n",
    "\n",
    "- ##### *spell_checker*\n",
    "    This is designed to correct spelling in a given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer()\n",
    "# stanza.download('fa')\n",
    "# nlp = stanza.Pipeline('fa', processors='tokenize,pos,lemma,depparse,ner')\n",
    "# spell_checker = SpellChecker()\n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    if isinstance(text, str):\n",
    "        \n",
    "        text = re.sub(r'[^آ-ی\\s]', '', text)\n",
    "        \n",
    "        text = normalizer.normalize(text)\n",
    "        \n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        \n",
    "        text = re.sub(r'[^\\w\\s]', '', text) \n",
    "        text = re.sub(r'\\d+', '', text) \n",
    "        text = text.lower() \n",
    "        \n",
    "        tokens = word_tokenize(text)\n",
    "        \n",
    "        tokens = [token for token in tokens if token not in persian_stopwords]\n",
    "        \n",
    "        return ' '.join(tokens)\n",
    "    else:\n",
    "        return ''\n",
    "        \n",
    "def normalize_text(text):\n",
    "    text = text.replace('ك', 'ک').replace('ي', 'ی')\n",
    "    text = text.translate(str.maketrans('0123456789', '۰۱۲۳۴۵۶۷۸۹'))\n",
    "    return text\n",
    "    \n",
    "def remove_diacritics(text):\n",
    "    diacritics = re.compile(\"[\\u064B-\\u0652]\")\n",
    "    text = re.sub(diacritics, '', text)\n",
    "    return text\n",
    "\n",
    "def preprocess_with_stanza(text):\n",
    "    doc = nlp(text)\n",
    "    processed_text = []\n",
    "    for sentence in doc.sentences:\n",
    "        for word in sentence.words:\n",
    "            processed_text.append({\n",
    "                'text': word.text,\n",
    "                'lemma': word.lemma,\n",
    "                'upos': word.upos,  \n",
    "                'xpos': word.xpos,  \n",
    "                'head': word.head,\n",
    "                'deprel': word.deprel, \n",
    "                'ner': word.ner, \n",
    "            })\n",
    "    return processed_text\n",
    "\n",
    "\n",
    "def named_entity_recognition(text):\n",
    "    stanza.download('fa')\n",
    "    nlp = stanza.Pipeline('fa')\n",
    "    doc = nlp(text)\n",
    "    for sentence in doc.sentences:\n",
    "        for entity in sentence.ents:\n",
    "            print(f\"Entity: {entity.text}, Type: {entity.type}\")\n",
    "    \n",
    "        for word in sentence.words:\n",
    "            print(f\"Word: {word.text}, Head: {word.head}, Deprel: {word.deprel}\")\n",
    "\n",
    "def extract_relations(doc):\n",
    "    relations = []\n",
    "    for sentence in doc.sentences:\n",
    "        entities = [(entity.text, entity.type) for entity in sentence.ents]\n",
    "        if len(entities) < 2:\n",
    "            continue  \n",
    "\n",
    "        for word in sentence.words:\n",
    "            if word.deprel in [\"nsubj\", \"obj\", \"iobj\", \"amod\"]: \n",
    "                head_word = sentence.words[word.head - 1]\n",
    "                if head_word.ner != \"O\" and word.ner != \"O\":\n",
    "                    relations.append((head_word.text, word.text, word.deprel))\n",
    "\n",
    "    for relation in relations:\n",
    "        print(f\"Relation: {relation}\")\n",
    "    return relations\n",
    "    \n",
    "def extract_entities(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    tagger = POSTagger(model='resources/postagger.model')\n",
    "    tagged_words = tagger.tag(tokens)\n",
    "    \n",
    "    entities = []\n",
    "    current_entity = []\n",
    "    current_tag = None\n",
    "    \n",
    "    for word, tag in tagged_words:\n",
    "        if tag.startswith('B-'):\n",
    "            if current_entity:\n",
    "                entities.append((' '.join(current_entity), current_tag))\n",
    "                current_entity = []\n",
    "            current_entity.append(word)\n",
    "            current_tag = tag[2:]\n",
    "        elif tag.startswith('I-'):\n",
    "            current_entity.append(word)\n",
    "        else:\n",
    "            if current_entity:\n",
    "                entities.append((' '.join(current_entity), current_tag))\n",
    "                current_entity = []\n",
    "            current_tag = None\n",
    "    \n",
    "    if current_entity:\n",
    "        entities.append((' '.join(current_entity), current_tag))\n",
    "    \n",
    "    return normalized_text, entities\n",
    "    \n",
    "def spell_checker(text):\n",
    "    tokens = text.split()\n",
    "    corrected_text = []\n",
    "    for token in tokens:\n",
    "        corrected_token = spell_checker.correct(token)\n",
    "        corrected_text.append(corrected_token)\n",
    "    \n",
    "    corrected_sentence = ' '.join(corrected_text)\n",
    "    return corrected_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nlpaug.augmenter.word as naw\n",
    "# def augment_text(text, aug_type='synonym'):\n",
    "#     augmenter = naw.SynonymAug(aug_src='wordnet')\n",
    "#     augmented_text = augmenter.augment(text)\n",
    "#     return augmented_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preproccess():\n",
    "    df['cleaned_text'] = df['text'].apply(clean_text)\n",
    "    df['cleaned_text'] = df['cleaned_text'].apply(normalize_text)\n",
    "    df['cleaned_text'] = df['cleaned_text'].apply(remove_diacritics)\n",
    "    # df['cleaned_text'] = df['cleaned_text'].apply(preprocess_with_stanza)\n",
    "    # df['cleaned_text'] = df['cleaned_text'].apply(named_entity_recognition)\n",
    "    # df['cleaned_text'] = df['cleaned_text'].apply(spell_checker)\n",
    "    # df['cleaned_text'] = df['cleaned_text'].apply(augment_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, instead of manipulating the data and adding a line above the rest of the lines\n",
    "I created two new columns, one of which is the text column and the other is the label column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text']=df.iloc[:,0]\n",
    "df['label']=df.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    text = row['text']\n",
    "    label = row['label']\n",
    "    normalized_text, entities = extract_entities(text)\n",
    "    print(f\"Text: {normalized_text}\")\n",
    "    print(f\"Entities: {entities}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"۱۲۳ امتحان می‌کنیم\"\n",
    "cleaned_tokens = clean_text(text)\n",
    "print(cleaned_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preproccess()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_counts = Counter()\n",
    "for text in df['cleaned_text']:\n",
    "    tokens = text.split()\n",
    "    word_counts.update(tokens)\n",
    "word_counts    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we count the number of types of words and the number of times each word appears\n",
    "Then, for a better and more practical view, we keep the words that have been repeated at least 100 times and then sort them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_word_counts = {word: freq for word, freq in word_counts.items() if freq >= 100}\n",
    "filtered_word_counts = dict(sorted(filtered_word_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "filtered_word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we count the number of types of words and the number of times each word appears\n",
    "Then, for a better and more practical view, we keep the words that have been repeated at least 100 times and then sort them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(filtered_word_counts.keys(), filtered_word_counts.values())\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Word Frequency in texts(>100)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, according to this graph, it is clear that most of the texts have the **happy** label\n",
    "And also the lowest number of that **Fear** label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dist = df['label'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "class_dist.plot(kind='bar', color=['blue', 'green'])\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('Class Distribution')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = CountVectorizer()\n",
    "X_bow = bow.fit_transform(df['cleaned_text'])\n",
    "X_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer (bow): Counts how often each word appears in each document.\n",
    "\n",
    "TfidfVectorizer (tfidf): Measures how important each word is to a document compared to the entire collection, accounting for word frequency and rarity across documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "X_tfidf = tfidf.fit_transform(df['cleaned_text'])\n",
    "X_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‌\n",
    "\n",
    "Encode categorical labels (df['label']) into numerical values suitable for machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(df['label'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bow, y, test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, from here on, I will train several different models on the data to compare their efficiency\n",
    "\n",
    "These models include\n",
    "\n",
    "*Decision tree*, *Random forest*, *GradientBoosting*, *LogisticRegression*, *MultinomialNB* and *XGBoost*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "dt_pred = dt_model.predict(X_test)\n",
    "\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, dt_pred))\n",
    "print(classification_report(y_test, dt_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, rf_pred))\n",
    "print(classification_report(y_test, rf_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "gb_preds = gb_model.predict(X_test)\n",
    "\n",
    "print(\"Gradient Boosting Accuracy:\", accuracy_score(y_test, gb_preds))\n",
    "print(classification_report(y_test, gb_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = VotingClassifier(estimators=[('rf', rf_model), ('gb', gb_model)], voting='hard')\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ensemble_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Ensemble Model Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression(max_iter=1000)\n",
    "log_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = log_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "params = {\n",
    "    'max_depth': 3,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': len(encoder.classes_), \n",
    "    'eval_metric': 'merror'  \n",
    "}\n",
    "\n",
    "num_rounds = 100 \n",
    "xgb_model = xgb.train(params, dtrain, num_boost_round=num_rounds)\n",
    "xgb_preds = xgb_model.predict(dtest)\n",
    "\n",
    "decoded_preds = encoder.inverse_transform(xgb_preds.astype(int))\n",
    "\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, xgb_preds))\n",
    "print(classification_report(y_test, xgb_preds, target_names=encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'multi:softmax',  \n",
    "    'num_class': len(encoder.classes_), \n",
    "    'eval_metric': 'merror', \n",
    "    'max_depth': 6,\n",
    "    'eta': 0.3,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8\n",
    "}\n",
    "num_rounds = 100\n",
    "nfold = 5\n",
    "early_stopping_rounds = 20\n",
    "\n",
    "cv_results = xgb.cv(params, dtrain, num_rounds, nfold=nfold, early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n",
    "best_num_rounds = len(cv_results) \n",
    "final_model = xgb.train(params, dtrain, best_num_rounds)\n",
    "xgb_preds = final_model.predict(dtest)\n",
    "\n",
    "decoded_preds = encoder.inverse_transform(xgb_preds.astype(int))\n",
    "\n",
    "print(\"Best num rounds XGBoost Accuracy:\", accuracy_score(y_test, xgb_preds))\n",
    "print(classification_report(y_test, xgb_preds, target_names=encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(cv_results.index, cv_results['train-merror-mean'], yerr=cv_results['train-merror-std'], label='Train')\n",
    "plt.errorbar(cv_results.index, cv_results['test-merror-mean'], yerr=cv_results['test-merror-std'], label='Validation')\n",
    "plt.xlabel('Boosting Round')\n",
    "plt.ylabel('Error Rate')\n",
    "plt.title('Training and Validation Error Rates')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After comparing all these models and trying to improve the efficiency and increase the accuracy percentage and change the parameters and the number of rounds\\\n",
    "It can be seen with a slight difference that the best of these models are the following models:\n",
    "\n",
    "**Gradient Boosting** , **Ensemble Model**, **XGBoost** and **Multinomial Naive Bayes** with about **60%** accuracy and best of them is ***Logistic Regression*** with ***62%*** accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
